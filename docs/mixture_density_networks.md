## Mixture Models
En est√° p√°gina se explica **los modelos de mixturas** como soluci√≥n t√©cnica para aproximar distribuciones heterog√©neas de la variable respuesta. Este es el caso en el que sabemos que los datos u observaciones provienen de fuentes o procesos diferentes conocidos.


### Indice de contenidos
- [Introducci√≥n a la t√©cnica](#introduccion)
- [Mixture Density Networks](#mdn)
- [MLE - Maximum Likelihood Estimation](#MLE) 

<a name="introduccion"></a>
## Introducci√≥n

Un **modelo de mixturas** es un modelo probabil√≠stico que nos permite representar la presencia de sub-poblaciones de la poblaci√≥n general. Esta representaci√≥n de sub-poblaciones nos va a permitir construir un estimador m√°s robusto en el caso en el que la distribuci√≥n de la variable respuesta sea heterog√©nea


<a name="mdn"></a>
### Mixture Density Networks

Las **redes de densidad mixta** (Bishop, 1994) es un tipo de red que combina las redes convencionales con el concepto de modelo de mixturas. En este modelo, la s√°lida de la DNN hace la estimaci√≥n de par√°metros para la familia de distribuciones o componentes seleccionadas las cuales se suman teniendo en cuenta el coeficiente de mezcla ‚ç∫ para obtener finalmente una distribucci√≥n condicional het√©rogena de y respecto a la entrada: 

<p align="center"><img src="/docs/assets/mdn/MDN.png" height="160" alt=‚ÄúMixture Density Network‚Äù /></p>
<p align="center">Mixture Density Network</p>

Formalmente la probabilidad condicionada de una red de mixturas tiene la siguiente forma:

<p align="center"><img src="/docs/assets/mdn/mdn_formula.png" height="70" alt=‚ÄúFormula MDN" /></p>
<p align="center">Mixture Density Network</p>

En esta f√≥rmula los par√°metros tiene la siguiente sem√°ntica:

* **c se corresponde con el √≠ndice de la correspondiente mixtura**. Hay hasta C componentes de mixtura (e.g. distribuciones) por salida, siendo un parametro seleccionable.
* **‚ç∫ es el coeficiente de mezcla**. Para entender este coeficiente podemos imaginarnos los controles deslizantes que controlan la mezcla de C salidas diferentes de audio. Este par√°metro esta condicionado por la entrada x.
* **ùíü esta es la correspondiente distribuci√≥n de entrada a ser mezclada**. La distribuci√≥n puede ser elegida atendiendo al tipo de aplicaci√≥n.
* **Œª son los par√°metros de la distribuci√≥n ùíü**. En el caso denotamos ùíü como una distribuci√≥n gausiana, estos parametros corresponderian a Œª1 ser√≠a la media condicional mean Œº(x) y 
Œª2 la desviaci√≥n est√°ndar œÉ(x). Las distribuciones pueden tener distinto n√∫mero de par√°metros (e.g.: Bernoulli and Chi2 tienen 1 par√°metro, Beta tiene 2, y la gaussiana truncada tiene hasta 4 par√°metros) Estos son par√°metros que forman tambi√©n la salida de la red.

<a name="MLE"></a>
### MLE - Maximum Likelihood Estimation

El algoritmo de MLE o m√°xima verosimilitud nos permite obtener los par√°metros del modelo o distribuci√≥n que maximizan la probabibilidad de obtener unos datos dados.

Referencia - [Ejemplo de c√°lculo de MLE para la implementaci√≥n de la funci√≥n de p√©rdida](https://d3c33hcgiwev3.cloudfront.net/_f678abd2f50f7171a76c7cb3ec03f726_MLE-for-Gaussian.pdf?Expires=1594252800&Signature=lDPX5Y6JT03mRyNj65JYEMZ7gjQuP5oXy-7019GmL8e8VuYRLo07K-N1iGU3geREMr1xj-VwjEh4qsV4R~PDQRpQuoH~UvEnrlpC3NyCzlgd1vcAKFQkppHqMXWsLDSg8HLu796cvDiu0R8bKy24ppHRdF4dta7sJCb3tvF8P8c_&Key-Pair-Id=APKAJLTNE6QMUY6HBC5A)


### Aplicaciones

Entre las **aplicaciones m√°s destacadas** se encuentra la de Apple‚Äôs Siri en iOS 11 para reconocimiento de voz[2]. En [3] se puede ver su aplicaci√≥n en generaci√≥n de manuscritos y Amazon Forecast lo tiene dentro su suite de algoritmos incluidos en su plataforma.

### Ventajas y desventajas

* *Ventajas* 

Permite estimar distribuciones heterog√©neas de la variable respuesta

* *Desventajas* 

El tama√±o de la s√°lida de la red creada por la capa final de la MDN es (c+2)* m, d√≥nde c es la dimensi√≥n de s√°lida de la red convencional y m el n√∫mero de mixturas que estamos usando. Esto supone un incremento considerable en la dimensi√≥n de s√°lida respecto a la red convencional lo que puede volverlas muy inestables.

#### Referencias

[1] https://towardsdatascience.com/a-hitchhikers-guide-to-mixture-density-networks-76b435826cca

[2] Siri Team, Deep Learning for Siri‚Äôs Voice: On-device Deep Mixture Density Networks for Hybrid Unit Selection Synthesis (2017)

[3] Alex Graves, Generating Sequences With Recurrent Neural Networks (2014)
