{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Predicting uncertainty with (deep) neural networks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Selected Distribution - Standard Exponential"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hypothesis: \n",
    "    - Do we obtain better results if we try to learn lambda (exp.parameter) instead of the variance (gaussian)?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://math.stackexchange.com/questions/101481/calculating-maximum-likelihood-estimation-of-the-exponential-distribution-and-pr"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**NOTE**: This notebook has been adapted from the original version : https://github.com/sthorn/deep-learning-explorations/blob/master/predicting-uncertainty.ipynb*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imports "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "from torch.autograd import Variable\n",
    "import torch.nn.functional as F\n",
    "import statistics as stat\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generate some random data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "# Generate some linearly related data\n",
    "np.random.seed(2019)\n",
    "\n",
    "n_samples = 10000\n",
    "x = np.random.standard_exponential(n_samples)\n",
    "\n",
    "sin_ = 0.4 * np.sin(x*4*np.pi)\n",
    "eps = np.random.standard_exponential(size=n_samples) * sin_ # noise\n",
    "y_1 = 2*x + 1 \n",
    "y = y_1 + eps # linear data with noise"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Describe the generated data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "# Plot the data\n",
    "plt.figure(figsize=(14,6))\n",
    "plt.title('Generated synthetic data')\n",
    "\n",
    "# plot data (with and without noise addition) \n",
    "plt.plot(x, y_1, '.', alpha=0.2, color='black' ) \n",
    "plt.plot(x, y, '.', alpha=0.2, color='green' ) \n",
    "\n",
    "plt.legend([r'data without noise',r'data with noise', r'$\\mu$', r'$\\pm\\sigma$'])\n",
    "plt.xlabel(r'$x$');\n",
    "plt.ylabel(r'$y$');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prepare data for training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "# Add in column of dummy zeros to represent sigma \n",
    "sigma = np.zeros(y.size)\n",
    "y = np.stack([y, sigma], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "# Reshape x for PyTorch\n",
    "#x = x.reshape(10000, 1)\n",
    "x = x.reshape(x.size, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "# Split into training and validation sets\n",
    "n_validation = 500\n",
    "x_val, x = x[:n_validation], x[n_validation:]\n",
    "y_val, y = y[:n_validation], y[n_validation:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "# Plot the data\n",
    "plt.figure(figsize=(14,6))\n",
    "plt.title('Training and validation sets')\n",
    "plt.plot(x, y, '.', color= 'green')\n",
    "plt.plot(x_val, y_val, '.', color='purple')\n",
    "plt.xlabel(r'$x$');\n",
    "plt.ylabel(r'$y$');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "# Convert x and y to PyTorch Variables on the GPU\n",
    "dtype = torch.cuda.FloatTensor\n",
    "x_t = Variable(torch.from_numpy(x).type(dtype))\n",
    "y_t = Variable(torch.from_numpy(y).type(dtype), requires_grad=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "# Check shape ok for PyTorch - x should be (n x 1), y (n x 2)\n",
    "x_t.shape, y_t.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Experiment "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create a simple network "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "# Create a simple two-layer network with one input (x) and two outputs (y, sigma)\n",
    "n_inputs = 1\n",
    "n_outputs = 2\n",
    "n_hidden = 1000\n",
    "model_1 = torch.nn.Sequential(torch.nn.Linear(n_inputs, n_hidden),\n",
    "                            torch.nn.ReLU(),\n",
    "                            torch.nn.Linear(n_hidden, n_outputs)\n",
    "                           ).cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "# Adam optimizer\n",
    "learning_rate = 1e-4\n",
    "optimizer = torch.optim.Adam(model_1.parameters(), lr=learning_rate)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Custom loss function\n",
    "This is where the magic happens."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "def loss_variance_error(input, target):\n",
    "    \n",
    "    # Estimate target value for variance (sigma^2) with (y_pred - y)**2\n",
    "    #\n",
    "    #    actual y        is target[:,0]\n",
    "    # predicted y        is input[:,0]\n",
    "    #    actual variance is target[:,1] - estimated here\n",
    "    # predicted variance is input[:,0]\n",
    "    \n",
    "    # Use 'requires_grad == False' to prevent PyTorch from trying to differentiate 'target'\n",
    "    target[:,1] = Variable((input[:,0].data - target[:,0].data)**2, \n",
    "                           requires_grad=False)  \n",
    "    # Return MSE loss \n",
    "    return F.mse_loss(input, target)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training loop \n",
    "We train this simple model with batch size equal to the whole dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "n_epochs = 10000\n",
    "for i in range(n_epochs):\n",
    "    \n",
    "    # Calculate predicted y from x\n",
    "    y_pred = model_1(x_t)\n",
    "    \n",
    "    # Calculate loss\n",
    "    loss = loss_variance_error(y_pred, y_t)\n",
    "    if i%500 == 0: print(f'epoch: {i:4} loss: {loss.data.item():.3}',)\n",
    "\n",
    "    # Backprop, first zeroing gradients\n",
    "    optimizer.zero_grad()\n",
    "    loss.backward()\n",
    "\n",
    "    # Update parameters\n",
    "    optimizer.step()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get predictions for validation set "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "# Get predicted y and sigma for validation set\n",
    "x_val_t = Variable(torch.from_numpy(x_val).type(dtype)) \n",
    "pred_1 = model_1(x_val_t)\n",
    "\n",
    "# prediction of the response variables\n",
    "y_pred_1 = pred_1[:,0].cpu().data\n",
    "sigma_pred_1 = pred_1[:,1].cpu().data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plot results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "# Plot predictions and their errors\n",
    "fig, ax1 = plt.subplots(figsize=(14,6))\n",
    "\n",
    "ax1.plot(x, y[:,0], '.', alpha=0.4, color='pink')\n",
    "ax1.plot(x_val, y_val[:,0], '.', color='blue')\n",
    "ax1.plot(x_val, y_pred_1, '.', color='purple')\n",
    "ax1.errorbar(x_val, y_pred_1, yerr=sigma_pred_1, fmt='.k');\n",
    "\n",
    "ax1.set_xlabel(r'$x$');\n",
    "ax1.set_ylabel(r'$y$');\n",
    "ax1.set_title('Validation set predictions');\n",
    "ax1.legend([r'Training', r'Validation', r'Prediction of y','Prediction of $\\pm \\sigma$'], loc='upper left', );"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "# Plot predictions and their errors\n",
    "fig, ax1 = plt.subplots(figsize=(14,6))\n",
    "ax1.plot(x_val, y_val[:,0], '.', color='purple')\n",
    "ax1.errorbar(x_val, y_val[:,0], yerr=sigma_pred_1.sqrt() , color='pink', fmt='.'); \n",
    "ax1.errorbar(x_val, y_pred_1, yerr=sigma_pred_1.sqrt() , color='green', fmt='.'); \n",
    "\n",
    "# One standard-deviation envelope\n",
    "plt.xlabel(r'$x$');\n",
    "plt.ylabel(r'$y$');\n",
    "plt.title('Validation set predictions');\n",
    "plt.legend([r'Original data','Validation set predictions'], loc='upper left', );"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Is it the predicted variance error distribution equals to the real variance error distirbution?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Predicted variance error distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "sns.distplot(sigma_pred_1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Generated error distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "sns.distplot(np.random.standard_exponential(size=n_samples))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Predicted y response variable distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "sns.distplot(y_pred_1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Real y distribution (validation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "sns.distplot(y_val[:,0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Real y distribution (training)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "sns.distplot(y[:,0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Real variance error distribution (validation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "real_sigma = (y_pred_1.numpy()- y_val[:,0])**2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "sns.distplot(real_sigma)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Real variance error distribution (training)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "real_sigma_train = (y_pred_1.numpy()- y[:500,0])**2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "sns.distplot(real_sigma_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Plot the real variance error "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "import math\n",
    "# Plot predictions and their errors\n",
    "fig, ax1 = plt.subplots(figsize=(14,6))\n",
    "\n",
    "ax1.plot(x_val, y_val[:,0], '.', color='purple')\n",
    "plt.errorbar(x_val, y_val[:,0], yerr=np.sqrt(real_sigma) , color='pink', fmt='.'); \n",
    "ax1.errorbar(x_val, y_pred_1, yerr=np.sqrt(real_sigma) , color='green', fmt='.'); \n",
    "\n",
    "# One standard-deviation envelope\n",
    "\n",
    "plt.title('Validation set predictions');\n",
    "plt.legend([r'Original data $\\pm \\sigma$ envelope','Validation set predictions'], loc='upper left');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Are the two (real and predicted error variance) distributions the same?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "source": [
    "#### Statistical tests to affirm the assumption extraced from plots "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "from scipy import stats"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Normality check with p-p plot and saphiro test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "stats.probplot(real_sigma, fit=True, rvalue=True, plot=plt);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "stats.probplot(sigma_pred_1, fit=True, rvalue=True, plot=plt);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "stats.shapiro(sigma_pred_1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Comparing the two distributions with Kolmogorov-Smirnov"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "stats.ks_2samp(sigma_pred_1, real_sigma)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can reject the null hypothesis: the two distribution are not identical"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "import pickle\n",
    "pickle.dump( x_val, open( \"x_val.p\", \"wb\" ) )\n",
    "pickle.dump( y_val, open( \"y_val.p\", \"wb\" ) )\n",
    "pickle.dump( y_pred_1, open( \"y_pred_1.p\", \"wb\" ) )\n",
    "pickle.dump( sigma_pred_1, open( \"sigma_pred_1.p\", \"wb\" ) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "from utilities import validation_metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "validation_metrics.overall_model_performance(x_val[:,0], y_val[:,0], y_pred_1, sigma_pred_1, std_factor=1/4, extreme_values_performance=True, display_plots=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "source": [
    "#### Evaluating the results with evaluation_metrics library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "validation_metrics.tests_prior_beliefs(x_val[:,0], y_val[:,0], y_pred_1, sigma_pred_1, data_pdf_expected=np.random.standard_exponential(size=n_samples), name_pdf_expected='Exponential Standard')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "stats.chisquare(sigma_pred_1, a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}