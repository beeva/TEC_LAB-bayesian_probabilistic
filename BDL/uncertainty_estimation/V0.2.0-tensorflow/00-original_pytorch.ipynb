{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Predicting uncertainty with (deep) neuralÂ networks\n",
    "\n",
    "The idea is that a network that outputs a real-valued prediction can be (simply) modified to provide an estimate of the error on this prediction. Roughly speaking we do:\n",
    "\n",
    "* Add an additional real-valued output to the network. The network now predicts two values: the output, $y$, and its error, $\\sigma$\n",
    "\n",
    "* Estimate the target value for the error, $\\sigma$, from the difference between the target value of the output, $y$, and its predicted value, $\\hat{y}$. We can use either: $\\sigma^2 = (y-\\hat{y})^2$ or $\\sigma = \\left| y-\\hat{y}\\right|$\n",
    "\n",
    "* An easy way to do this at training time is with a customised loss function"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imports "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "from torch.autograd import Variable\n",
    "import torch.nn.functional as F\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generate some random data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate some linearly related data\n",
    "n_samples = 10000\n",
    "x = np.random.random(n_samples)\n",
    "eps = np.random.normal(scale=1.0, size=n_samples) * 0.4*np.sin(x*4*np.pi)\n",
    "y = 2*x + 1 + eps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the data\n",
    "plt.figure(figsize=(14,6))\n",
    "plt.plot(x, y, '.')\n",
    "plt.xlabel(r'$x$');\n",
    "plt.ylabel(r'$y$');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add in column of dummy zeros to represent sigma \n",
    "sigma = np.zeros(10000)\n",
    "y = np.stack([y, sigma], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reshape x for PyTorch\n",
    "x = x.reshape(10000, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split into training and validation sets\n",
    "n_validation = 500\n",
    "x_val, x = x[:n_validation], x[n_validation:]\n",
    "y_val, y = y[:n_validation], y[n_validation:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the data\n",
    "plt.figure(figsize=(14,6))\n",
    "plt.plot(x, y, '.')\n",
    "plt.plot(x_val, y_val, '.')\n",
    "plt.xlabel(r'$x$');\n",
    "plt.ylabel(r'$y$');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert x and y to PyTorch Variables on the GPU\n",
    "dtype = torch.FloatTensor\n",
    "x = Variable(torch.from_numpy(x).type(dtype))\n",
    "y = Variable(torch.from_numpy(y).type(dtype), requires_grad=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check shape ok for PyTorch - x should be (n x 1), y (n x 2)\n",
    "x.shape, y.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create a simple network "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a simple two-layer network with one input (x) and two outputs (y, sigma)\n",
    "n_inputs = 1\n",
    "n_outputs = 2\n",
    "n_hidden = 1000\n",
    "model = torch.nn.Sequential(torch.nn.Linear(n_inputs, n_hidden),\n",
    "                            torch.nn.ReLU(),\n",
    "                            torch.nn.Linear(n_hidden, n_outputs)\n",
    "                           )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Adam optimizer\n",
    "learning_rate = 1e-4\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Custom loss function\n",
    "This is where the magic happens."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def custom_loss(input, target):\n",
    "    \n",
    "    # Estimate target value for sigma with abs(y_pred - y)\n",
    "    #\n",
    "    #    actual y     is target[:,0]\n",
    "    # predicted y     is input[:,0]\n",
    "    #    actual sigma is target[:,1]\n",
    "    # predicted sigma is input[:,0]\n",
    "    \n",
    "    # Use 'requires_grad == False' to prevent PyTorch from trying to differentiate 'target'\n",
    "    target[:,1] = Variable((input[:,0].data - target[:,0].data)**2, \n",
    "                           requires_grad=False)  \n",
    "    # Return MSE loss \n",
    "    return F.mse_loss(input, target)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training loop \n",
    "We train this simple model with batch size equal to the whole dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "n_epochs = 10000\n",
    "for i in range(n_epochs):\n",
    "    \n",
    "    # Calculate predicted y from x\n",
    "    y_pred = model(x)\n",
    "    \n",
    "    # Calculate loss\n",
    "    loss = custom_loss(y_pred, y)\n",
    "    if i%100 == 0:\n",
    "        print('epoch: {}, loss {}'.format(i, loss))\n",
    "\n",
    "    # Backprop, first zeroing gradients\n",
    "    optimizer.zero_grad()\n",
    "    loss.backward()\n",
    "\n",
    "    # Update parameters\n",
    "    optimizer.step()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get predictions for validation set "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get predicted y and sigma for validation set\n",
    "x_val_pytorch = Variable(torch.from_numpy(x_val).type(dtype)) \n",
    "pred = model(x_val_pytorch)\n",
    "y_pred = pred[:,0].cpu().data\n",
    "variance_pred = pred[:,1].cpu().data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plot results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Plot predictions and their errors\n",
    "plt.figure(figsize=(14,6))\n",
    "plt.errorbar(x_val, y_pred.numpy(), yerr=variance_pred.sqrt().numpy(), fmt='.');\n",
    "\n",
    "\n",
    "# One standard-deviation envelope\n",
    "xs = np.linspace(1.0, 10.0, 500)\n",
    "err = 0.4*np.sin(xs*4*np.pi)\n",
    "plt.fill_between(xs, 2*xs+1-err, 2*xs+1+err, facecolor='orange', alpha=0.5, edgecolor='none');\n",
    "plt.xlabel(r'$x$');\n",
    "plt.ylabel(r'$y$');\n",
    "plt.title('Validation set predictions');\n",
    "plt.legend([r'Original data $\\pm \\sigma$ envelope','Validation set predictions'], loc='upper left', );"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "z_samples = 10000\n",
    "z_x = np.random.random(z_samples)*10\n",
    "z_x_eps = np.random.normal(scale=1.0, size=z_samples) * 0.4*np.sin(z_x*4*np.pi)\n",
    "x_y = 2*z_x + 1 + z_x_eps\n",
    "z_x = z_x.reshape(10000, 1)\n",
    "\n",
    "\n",
    "z_pred = model( Variable(torch.from_numpy(z_x).type(dtype))  )\n",
    "z_y_pred = z_pred[:,0].cpu().data\n",
    "z_variance_pred = z_pred[:,1].cpu().data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "z_y_pred.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the data\n",
    "plt.figure(figsize=(14,6))\n",
    "plt.plot(x, y[:,0], '.')\n",
    "plt.plot(z_x, z_y_pred, '.')\n",
    "plt.plot(z_x, z_variance_pred, '.')\n",
    "plt.xlabel(r'$x$')\n",
    "plt.ylabel(r'$y$')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Plot predictions and their errors\n",
    "plt.figure(figsize=(140,60))\n",
    "plt.errorbar(z_x, z_y_pred.numpy(), yerr=z_variance_pred.sqrt().numpy(), fmt='.')\n",
    "\n",
    "# One standard-deviation envelope\n",
    "xs = np.linspace(1.0, 10.0, 500)\n",
    "err = 0.4*np.sin(xs*4*np.pi)\n",
    "plt.fill_between(xs, 2*xs+1-err, 2*xs+1+err, facecolor='orange', alpha=0.5, edgecolor='none');\n",
    "plt.xlabel(r'$x$');\n",
    "plt.ylabel(r'$y$');\n",
    "plt.title('Validation set predictions');\n",
    "plt.legend([r'Original data $\\pm \\sigma$ envelope','Validation set predictions'], loc='upper left', );"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
